{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0aa6bad-7a27-4bb0-bd84-e7ba939897c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully.\n",
      "             TYPE   PRICE  BEDS  BATH  PROPERTYSQFT         LOCALITY\n",
      "0  Co-op for sale  440000     2     1           978     Kings County\n",
      "1  Co-op for sale  375000     2     1           850     Bronx County\n",
      "2  Condo for sale  549000     2     2          1000  Richmond County\n",
      "3  Co-op for sale  199000     3     1           325     Kings County\n",
      "4  Co-op for sale  350000     1     1           700     Bronx County\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'clean_NY_Housing_data.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"CSV file loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {file_path} was not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e86764-b909-4395-8b98-81bde91dcdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.99521531 0.99521531 0.98564593 0.98564593 0.99521531]\n",
      "Mean cross-validation score: 0.9913875598086126\n",
      "Accuracy on test data: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       162\n",
      "\n",
      "    accuracy                           1.00       262\n",
      "   macro avg       1.00      1.00      1.00       262\n",
      "weighted avg       1.00      1.00      1.00       262\n",
      "\n",
      "Confusion Matrix:\n",
      "[[100   0]\n",
      " [  0 162]]\n"
     ]
    }
   ],
   "source": [
    "# Define the threshold price\n",
    "threshold_price = 500000\n",
    "\n",
    "# Add a new column 'Price_Above_Threshold' to classify properties based on the threshold price\n",
    "if 'PRICE' in df.columns:\n",
    "    df['Price_Above_Threshold'] = (df['PRICE'] > threshold_price).astype(int)\n",
    "else:\n",
    "    print(\"Error: 'PRICE' column not found in the dataset.\")\n",
    "    exit(1)\n",
    "\n",
    "# Define the target variable (above/below threshold) and features\n",
    "y = df['Price_Above_Threshold']\n",
    "X = df.drop(['Price_Above_Threshold', 'TYPE', 'LOCALITY'], axis=1)\n",
    "\n",
    "# Ensure there are no missing values\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model with regularization\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'solver': ['liblinear', 'lbfgs']}\n",
    "grid_search = GridSearchCV(lr_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Cross-validation on the best model\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "# Train the best model on the training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Accuracy on test data:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aaa4b7d-9fd5-45b2-a590-80b016e8f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to filtered_heatmap_data_with_predictions.json\n"
     ]
    }
   ],
   "source": [
    "# Add predictions to the original DataFrame\n",
    "df['Prediction'] = best_model.predict(scaler.transform(df.drop(['Price_Above_Threshold', 'TYPE', 'LOCALITY'], axis=1)))\n",
    "\n",
    "# Prepare the relevant columns for the JSON output\n",
    "relevant_columns = ['TYPE', 'PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT', 'LOCALITY', 'Prediction']\n",
    "\n",
    "# Check if all relevant columns are present in the dataset\n",
    "if not all(col in df.columns for col in relevant_columns):\n",
    "    missing_cols = [col for col in relevant_columns if col not in df.columns]\n",
    "    print(f\"Error: Missing columns in the dataset: {missing_cols}\")\n",
    "    exit(1)\n",
    "\n",
    "# Filter the dataframe to keep only the relevant columns\n",
    "data_for_json = df[relevant_columns]\n",
    "\n",
    "# Convert the DataFrame to a list of lists\n",
    "data_list = data_for_json.values.tolist()\n",
    "\n",
    "# Define the path for the JSON file\n",
    "json_file_path = 'filtered_heatmap_data_with_predictions.json'\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data_list, json_file)\n",
    "\n",
    "print(f'Data successfully written to {json_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d76c4c-5bd4-4e13-97d6-a0fb18f56c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
